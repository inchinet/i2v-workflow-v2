
document.addEventListener('DOMContentLoaded', () => {
    // --- Elements ---
    const dropFemale = document.getElementById('drop-female');
    const inputFemale = document.getElementById('female-photo');
    const previewFemale = document.getElementById('preview-female');

    const dropMale = document.getElementById('drop-male');
    const inputMale = document.getElementById('male-photo');
    const previewMale = document.getElementById('preview-male');

    // Scene textareas (10 total)
    const sceneInputs = [];
    const charCounters = [];
    for (let i = 1; i <= 10; i++) {
        sceneInputs.push(document.getElementById(`scene-${i}`));
        charCounters.push(document.getElementById(`char-${i}`));
    }

    const gallerySection = document.getElementById('gallery-section');
    const imageGallery = document.getElementById('image-gallery');

    const btnGenVideo = document.getElementById('btn-gen-video');
    const videoSection = document.getElementById('video-section');
    const finalVideo = document.getElementById('final-video');
    const apiKeyInput = document.getElementById('api-key');

    // --- API Key Persistence ---
    if (apiKeyInput) {
        // Load on startup
        const savedKey = localStorage.getItem('google_gemini_api_key');
        if (savedKey) {
            apiKeyInput.value = savedKey;
            console.log("å·²å¾å„²å­˜è¼‰å…¥ API é‡‘é‘°ã€‚");
        }
        // Save on change
        apiKeyInput.addEventListener('input', () => {
            localStorage.setItem('google_gemini_api_key', apiKeyInput.value.trim());
        });
    }

    // --- State ---
    const state = {
        femaleImg: null,
        maleImg: null,
        scenes: [] // Array of user-provided scene descriptions
    };

    // --- Helpers ---
    const handleFileSelect = (file, previewContainer, key, dropZone = null) => {
        if (!file) return;

        console.log(`æ­£åœ¨è™•ç† ${key} çš„æª”æ¡ˆ:`, file.name);

        // Update UI Text if dropZone provided
        if (dropZone) {
            const msgSpan = dropZone.querySelector('.file-msg');
            if (msgSpan) {
                msgSpan.innerHTML = `<i class="fa-solid fa-check" style="color:#4CAF50;"></i> ${file.name}`;
                dropZone.style.borderColor = '#4CAF50';
            }
        }

        const reader = new FileReader();
        reader.onload = (e) => {
            state[key] = e.target.result;
            // Clear previous content
            previewContainer.innerHTML = '';

            if (file.type.startsWith('image/')) {
                const img = document.createElement('img');
                img.src = e.target.result;
                img.alt = "é è¦½";
                img.style.display = 'block';
                previewContainer.appendChild(img);
            } else if (file.type.startsWith('video/')) {
                const video = document.createElement('video');
                video.src = e.target.result;
                video.controls = true;
                video.muted = true;
                video.style.display = 'block';
                video.style.width = '100%';
                video.style.borderRadius = '8px';
                previewContainer.appendChild(video);
            }
            console.log(`${key} é è¦½å·²æ›´æ–°`);
        };
        reader.onerror = (err) => console.error("æª”æ¡ˆè®€å–éŒ¯èª¤:", err);
        reader.readAsDataURL(file);
    };

    const setupDragDrop = (dropZone, input, previewContainer, key) => {
        // Method 1: Click to Upload (Trigger hidden input)
        dropZone.addEventListener('click', (e) => {
            // Avoid infinite loop if clicking the input itself bubbles to div
            if (e.target !== input) {
                input.click();
            }
        });

        input.addEventListener('change', (e) => {
            console.log('æª”æ¡ˆè¼¸å…¥å·²è®Šæ›´', key);
            if (e.target.files && e.target.files[0]) {
                handleFileSelect(e.target.files[0], previewContainer, key, dropZone);
            }
        });

        // Method 2: Drag & Drop (Manual Handling)
        ['dragenter', 'dragover', 'dragleave', 'drop'].forEach(eventName => {
            dropZone.addEventListener(eventName, (e) => {
                e.preventDefault();
                e.stopPropagation();
            }, false);
        });

        // Highlight
        ['dragenter', 'dragover'].forEach(eventName => {
            dropZone.addEventListener(eventName, () => {
                dropZone.style.borderColor = 'var(--primary-color)';
                dropZone.style.background = 'rgba(255, 255, 255, 0.15)';
            }, false);
        });

        // Un-highlight
        ['dragleave', 'drop'].forEach(eventName => {
            dropZone.addEventListener(eventName, () => {
                dropZone.style.borderColor = 'rgba(255, 255, 255, 0.3)';
                dropZone.style.background = 'transparent';
            }, false);
        });

        // Handle Drop
        dropZone.addEventListener('drop', (e) => {
            const dt = e.dataTransfer;
            const files = dt.files;
            console.log('æª”æ¡ˆå·²æ‹–æ”¾åˆ°å€åŸŸ', key);
            if (files && files[0]) {
                handleFileSelect(files[0], previewContainer, key, dropZone);
                // Also update input in case form submission is needed (optional)
                input.files = files;
            }
        }, false);
    };

    // --- Init Drag & Drop ---
    setupDragDrop(dropFemale, inputFemale, previewFemale, 'femaleImg');
    setupDragDrop(dropMale, inputMale, previewMale, 'maleImg');

    // --- Text Input for 10 scenes ---
    sceneInputs.forEach((textarea, idx) => {
        if (!textarea) return;
        textarea.addEventListener('input', (e) => {
            const counter = charCounters[idx];
            if (counter) {
                counter.textContent = e.target.value.length;
            }
        });
    });

    // --- Dialogue to Narrative Converter ---
    const convertDialogueToNarrative = async (dialogueText, sceneNumber) => {
        const apiKey = document.getElementById('api-key').value.trim();

        if (!apiKey) {
            alert('è«‹å…ˆè¼¸å…¥ Google Gemini API é‡‘é‘°ä»¥ä½¿ç”¨å°ç™½è½‰æ›åŠŸèƒ½ã€‚');
            return null;
        }

        if (!dialogueText.trim()) {
            alert('å ´æ™¯æè¿°ç‚ºç©ºï¼Œç„¡éœ€è½‰æ›ã€‚');
            return null;
        }

        // Check if there's a structured dialogue section
        const dialogueMatch = dialogueText.match(/\*\*Dialogue:\*\*\s*([\s\S]*?)(?=\n\n|$)/i);

        let textToConvert;
        let hasStructuredDialogue = false;

        if (dialogueMatch) {
            // Found structured dialogue section
            textToConvert = dialogueMatch[1].trim();
            hasStructuredDialogue = true;
        } else {
            // Check for simple dialogue format (é˜¿æ˜: ... é˜¿èŠ±: ...)
            const simpleDialoguePattern = /[\u4e00-\u9fff]+:\s*\([^)]*\)|[\u4e00-\u9fff]+:\s*.+/;
            if (simpleDialoguePattern.test(dialogueText)) {
                textToConvert = dialogueText;
            } else {
                // Already in narrative format or no dialogue found
                alert('æœªæª¢æ¸¬åˆ°å°ç™½æ ¼å¼ã€‚å ´æ™¯æè¿°ä¼¼ä¹å·²ç¶“æ˜¯æ•˜è¿°æ ¼å¼ï¼Œæˆ–æ²’æœ‰æ‰¾åˆ°å°ç™½éƒ¨åˆ†ã€‚');
                return null;
            }
        }

        try {
            const prompt = `ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„é›»å½±å ´æ™¯æè¿°è½‰æ›åŠ©æ‰‹ã€‚è«‹å°‡ä»¥ä¸‹åŠ‡æœ¬æ ¼å¼çš„å°ç™½è½‰æ›ç‚ºæ•˜è¿°æ€§çš„å ´æ™¯æè¿°ï¼Œé©åˆç”¨æ–¼ AI å½±ç‰‡ç”Ÿæˆã€‚

é‡è¦è¦å‰‡ï¼š
1. å°‡è§’è‰²åç¨±è½‰æ›ç‚º"ç”·ä¸»è§’"æˆ–"å¥³ä¸»è§’"ï¼ˆå¦‚æœæœ‰å…·é«”åå­—ï¼Œä¿ç•™åå­—ï¼Œä¾‹å¦‚"ç”·ä¸»è§’é˜¿æ˜"ã€"å¥³ä¸»è§’é˜¿èŠ±"ï¼‰
2. ä¿ç•™æ‰€æœ‰æƒ…æ„Ÿæè¿°å’Œå‹•ä½œæŒ‡ç¤º
3. å°‡å°ç™½å…§å®¹è½‰æ›ç‚ºæ•˜è¿°å½¢å¼ï¼Œæè¿°è§’è‰²èªªäº†ä»€éº¼
4. ä¿æŒå»£æ±è©±ç”¨è©å’Œèªæ°£
5. åœ¨çµå°¾æ·»åŠ "ä¿æŒäººç‰©å®¹è²Œ, é«®å‹è¡£ç€, åŒ–å¦ã€‚"
6. åªè¼¸å‡ºè½‰æ›å¾Œçš„å ´æ™¯æè¿°ï¼Œä¸è¦æ·»åŠ ä»»ä½•è§£é‡‹æˆ–é¡å¤–æ–‡å­—

åŸå§‹å°ç™½ï¼š
${textToConvert}

è½‰æ›å¾Œçš„å ´æ™¯æè¿°ï¼š`;

            const url = `https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash-exp:generateContent?key=${apiKey}`;

            const response = await fetch(url, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({
                    contents: [{
                        parts: [{ text: prompt }]
                    }]
                })
            });

            const data = await response.json();

            if (data.error) {
                throw new Error(data.error.message || 'è½‰æ›å¤±æ•—');
            }

            if (data.candidates && data.candidates[0].content && data.candidates[0].content.parts) {
                const convertedText = data.candidates[0].content.parts[0].text.trim();

                // If there was a structured dialogue section, replace only that part
                if (hasStructuredDialogue) {
                    const updatedText = dialogueText.replace(
                        /\*\*Dialogue:\*\*\s*[\s\S]*?(?=\n\n|$)/i,
                        `**Narrative Description:**\n${convertedText}`
                    );
                    return updatedText;
                } else {
                    // Return just the converted text
                    return convertedText;
                }
            }

            throw new Error('ç„¡æ³•å¾ API éŸ¿æ‡‰ä¸­æå–è½‰æ›çµæœ');

        } catch (error) {
            console.error('å°ç™½è½‰æ›éŒ¯èª¤:', error);
            alert(`è½‰æ›å¤±æ•—: ${error.message}`);
            return null;
        }
    };

    // --- Setup Convert Buttons ---
    const convertButtons = document.querySelectorAll('.convert-btn');
    convertButtons.forEach(btn => {
        btn.addEventListener('click', async () => {
            const sceneNumber = btn.getAttribute('data-scene');
            const textarea = document.getElementById(`scene-${sceneNumber}`);

            if (!textarea) return;

            const originalText = textarea.value;

            // Disable button and show loading state
            btn.disabled = true;
            btn.classList.add('loading');
            const originalBtnText = btn.innerHTML;
            btn.innerHTML = '<i class="fa-solid fa-rotate"></i> è½‰æ›ä¸­...';

            try {
                const convertedText = await convertDialogueToNarrative(originalText, sceneNumber);

                if (convertedText) {
                    textarea.value = convertedText;
                    // Update character counter
                    const counter = charCounters[parseInt(sceneNumber) - 1];
                    if (counter) {
                        counter.textContent = convertedText.length;
                    }
                    // Brief success feedback
                    btn.innerHTML = '<i class="fa-solid fa-check"></i> å·²è½‰æ›';
                    setTimeout(() => {
                        btn.innerHTML = originalBtnText;
                    }, 2000);
                }
            } catch (error) {
                console.error('è½‰æ›éŒ¯èª¤:', error);
            } finally {
                btn.disabled = false;
                btn.classList.remove('loading');
                setTimeout(() => {
                    btn.innerHTML = originalBtnText;
                }, 2000);
            }
        });
    });


    // --- Helper: Collect User Scenes ---
    const collectUserScenes = () => {
        const scenes = [];
        const cameraMovesPattern = [
            "Wide Shot (å¤§é æ™¯)",
            "Mid Shot (ä¸­æ™¯)",
            "Close-up Female (å¥³è§’ç‰¹å¯«)",
            "Close-up Male (ç”·è§’ç‰¹å¯«)",
            "Dolly In (æ¨é¡)",
            "Pan (é‹é¡)",
            "Mid Shot (ä¸­æ™¯)",
            "Wide Shot (å¤§é æ™¯)",
            "Close-up Female (å¥³è§’ç‰¹å¯«)",
            "Dolly In (æ¨é¡)"
        ];

        sceneInputs.forEach((textarea, idx) => {
            if (!textarea) return;
            const text = textarea.value.trim();
            if (text.length > 0) {
                scenes.push({
                    idx: scenes.length,
                    description: text,
                    image_prompt_en: text, // Use same text for image generation
                    cameraMove: cameraMovesPattern[idx] || "Mid Shot (ä¸­æ™¯)",
                    transformId: getTransformId(cameraMovesPattern[idx] || "Mid Shot")
                });
            }
        });

        return scenes;
    };

    // Helper to map Move ID from Name
    const getTransformId = (moveName) => {
        if (!moveName) return 0;
        const n = moveName.toLowerCase();
        if (n.includes("wide") || n.includes("é æ™¯")) return 0;
        if (n.includes("dolly") || n.includes("æ¨é¡")) return 1;
        if (n.includes("female") && n.includes("close")) return 2;
        if (n.includes("å¥³è§’") && n.includes("ç‰¹å¯«")) return 2;
        if (n.includes("male") && n.includes("close")) return 3;
        if (n.includes("ç”·è§’") && n.includes("ç‰¹å¯«")) return 3;
        if (n.includes("mid") || n.includes("ä¸­æ™¯")) return 4;
        if (n.includes("pan") || n.includes("é‹é¡")) return 4;
        return 0; // Default Wide
    };

    // Helper: Production Logging
    const addProductionLog = (msg, type = 'info') => {
        const logContent = document.getElementById('log-content');
        const productionLogs = document.getElementById('production-logs');
        if (!logContent || !productionLogs) return;

        productionLogs.classList.remove('hidden');
        const entry = document.createElement('div');
        const timestamp = new Date().toLocaleTimeString();
        let color = '#00ffcc';
        if (type === 'warn') color = '#ffcc00';
        if (type === 'error') color = '#ff3333';
        if (type === 'success') color = '#33ff33';

        entry.innerHTML = `<span style="color:rgba(255,255,255,0.4);">[${timestamp}]</span> <span style="color:${color}">${msg}</span>`;
        logContent.appendChild(entry);
        logContent.scrollTop = logContent.scrollHeight;
    };

    // Helper: Robust Download
    const downloadImage = (dataUrl, filename) => {
        const link = document.createElement('a');
        link.href = dataUrl;
        fetch(dataUrl)
            .then(res => res.blob())
            .then(blob => {
                const url = window.URL.createObjectURL(blob);
                link.href = url;
                link.download = filename;
                document.body.appendChild(link);
                link.click();
                document.body.removeChild(link);
                window.URL.revokeObjectURL(url);
            })
            .catch(() => {
                // Fallback
                link.href = dataUrl;
                link.download = filename;
                link.click();
            });
    };
    // Expose to window for onclick
    window.downloadImage = downloadImage;

    // MODEL LOCK: Once a model succeeds, we reuse it for all scenes (consistency)
    let lockedImageModel = null;

    // Helper: Call Google Gemini for Image Generation (Dynamic Discovery)
    const generateAIImage = async (apiKey, prompt, referenceImageBase64 = null, onStatusUpdate = null, aspectRatio = "4:3", visualDetails = "") => {
        const sleep = (ms) => new Promise(r => setTimeout(r, ms));
        const allErrors = [];

        // MODEL LOCK CHECK: If we already found a working model, use it directly
        if (lockedImageModel) {
            console.log(`[åœ–åƒç”Ÿæˆ] ä½¿ç”¨é–å®šæ¨¡å‹: ${lockedImageModel}`);
            const candidatesIds = [lockedImageModel];

            const tryImgModel = async (idx) => {
                if (idx >= candidatesIds.length) {
                    console.error("é–å®šæ¨¡å‹å¤±æ•—ã€‚");
                    lockedImageModel = null;
                    throw new Error("é–å®šæ¨¡å‹å¤±æ•—ã€‚è«‹é‡æ–°ç”Ÿæˆã€‚");
                }

                const modelId = candidatesIds[idx];
                console.log(`[åœ–åƒç”Ÿæˆ] ä½¿ç”¨ ${modelId}...`);

                const url = `https://generativelanguage.googleapis.com/v1beta/models/${modelId}:generateContent?key=${apiKey}`;

                const parts = [];
                const aspectInstruction = aspectRatio === "3:4"
                    ? "å‚ç›´è‚–åƒæ ¼å¼ï¼ˆé«˜æ–¼å¯¬ï¼Œ3:4 æ¯”ä¾‹ï¼‰"
                    : "æ°´å¹³æ©«å‘æ ¼å¼ï¼ˆå¯¬æ–¼é«˜ï¼Œ4:3 æ¯”ä¾‹ï¼‰";

                let finalPrompt = '';

                // Append visual details if provided
                const visualContext = visualDetails ? `\n\nVISUAL & LOCATION CONSISTENCY LOCK (MANDATORY):\n${visualDetails}\nEnsure these visual details (appearance, environment, lighting) are strictly followed unless the scene description explicitly overrides them.` : "";

                // CRITICAL: Reference image instructions come FIRST for maximum priority
                if (referenceImageBase64) {
                    finalPrompt = `ğŸ”´ CRITICAL PRIORITY - FACIAL IDENTITY LOCK ğŸ”´

                    **MANDATORY REQUIREMENTS (HIGHEST PRIORITY):**
                    1. The person in the generated image MUST have the EXACT SAME FACE as the attached reference image
                    2. PRESERVE 100% FACIAL IDENTITY - same ethnicity, race, skin tone, facial structure, eye shape, nose, mouth
                    3. DO NOT change the person's race or ethnicity under ANY circumstances
                    4. This is the SAME PERSON performing in a movie scene - maintain complete facial consistency
                    5. Match the reference photo's hairstyle, hair color, and facial features precisely
                    6. If the reference shows an Asian person, the output MUST be Asian. If Caucasian, output MUST be Caucasian. If African, output MUST be African.
                    
                    ${visualContext}

                    **SCENE DESCRIPTION (Secondary Priority):**
                    Generate a photorealistic 8k image in ${aspectInstruction} format showing: ${prompt}
                    
                    **STYLE REQUIREMENTS:**
                    - Photorealistic photography style (çœŸå¯¦æ”å½±ç…§ç‰‡é¢¨æ ¼)
                    - Real human faces with skin texture
                    - Absolutely NO anime, illustration, cartoon, or painting styles
                    - Natural lighting and depth of field effects
                    
                    âš ï¸ REMINDER: The character's face, ethnicity, and race MUST match the reference image EXACTLY. This is non-negotiable.`;
                } else {
                    finalPrompt = `ç”Ÿæˆä¸€å¼µçœŸå¯¦ç…§ç‰‡ç´šåˆ¥çš„ 8k åœ–åƒï¼Œæ ¼å¼ç‚º ${aspectInstruction}ï¼Œå…§å®¹ï¼š${prompt}ã€‚
                    
                    ${visualContext}

                    é¢¨æ ¼è¦æ±‚ï¼š
                    - å¿…é ˆæ˜¯çœŸå¯¦æ”å½±ç…§ç‰‡é¢¨æ ¼ï¼ˆphotorealisticï¼‰
                    - çœŸå¯¦çš„äººé¡é¢å­”å’Œçš®è†šç´‹ç†
                    - çµ•å°ä¸è¦å‹•æ¼«ã€æ’ç•«ã€å¡é€šæˆ–ç¹ªç•«é¢¨æ ¼
                    - ä½¿ç”¨çœŸå¯¦çš„å…‰å½±å’Œæ™¯æ·±æ•ˆæœ`;
                }

                parts.push({ text: finalPrompt });

                if (referenceImageBase64) {
                    const b64Data = referenceImageBase64.split(',')[1] || referenceImageBase64;
                    const mimeType = referenceImageBase64.includes('image/png') ? 'image/png' : 'image/jpeg';
                    parts.push({ inlineData: { mimeType: mimeType, data: b64Data } });
                }

                const body = { contents: [{ parts: parts }] };

                try {
                    const response = await fetch(url, {
                        method: 'POST',
                        headers: { 'Content-Type': 'application/json' },
                        body: JSON.stringify(body)
                    });
                    const data = await response.json();

                    if (data.error) {
                        const msg = `[${modelId}] éŒ¯èª¤: ${data.error.message || JSON.stringify(data.error)}`;
                        console.warn(msg);
                        throw new Error(msg);
                    }

                    if (data.candidates && data.candidates[0].content && data.candidates[0].content.parts) {
                        for (const part of data.candidates[0].content.parts) {
                            if (part.inlineData && part.inlineData.mimeType.startsWith('image')) {
                                lockedImageModel = modelId;
                                return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
                            }
                        }
                    }

                    throw new Error(`[${modelId}] æˆåŠŸä½†éŸ¿æ‡‰ä¸­æ²’æœ‰åœ–åƒæ•¸æ“šã€‚`);
                } catch (e) {
                    throw e;
                }
            };

            return tryImgModel(0);
        }

        // 1. DYNAMIC MODEL DISCOVERY (First time only)
        let validModelIds = [];
        try {
            console.log("[å‹•æ…‹ç™¼ç¾] æ­£åœ¨ç²å–å¯ç”¨æ¨¡å‹...");
            const listRes = await fetch(`https://generativelanguage.googleapis.com/v1beta/models?key=${apiKey}`);
            const listData = await listRes.json();

            if (listData.models) {
                validModelIds = listData.models
                    .filter(m => m.supportedGenerationMethods && m.supportedGenerationMethods.includes("generateContent"))
                    .map(m => m.name.replace('models/', ''));

                console.log("[å‹•æ…‹ç™¼ç¾] å¯ç”¨ç”Ÿæˆå™¨:", validModelIds);
            }
        } catch (e) {
            console.warn("[å‹•æ…‹ç™¼ç¾] åˆ—å‡ºæ¨¡å‹å¤±æ•—ï¼Œä½¿ç”¨å¾Œå‚™ã€‚", e);
        }

        // 2. PRIORITY LOGIC
        const preferredPatterns = [
            'nano-banana-pro-preview',
            'gemini-3-pro-image-preview',
            'gemini-3-pro-preview',
            'veo-3',
            'gemini-2.0-flash-exp-image-generation',
            'imagen-4'
        ];

        let candidatesIds = [];

        preferredPatterns.forEach(pattern => {
            const matches = validModelIds.filter(id => id.includes(pattern));
            candidatesIds.push(...matches);
        });

        if (candidatesIds.length === 0) {
            candidatesIds = [
                "gemini-2.0-flash-exp-image-generation",
                "nano-banana-pro-preview",
                "gemini-2.5-flash-image-preview",
                "gemini-2.5-flash-image",
                "gemini-3-pro-image-preview",
                "gemini-2.0-flash-exp",
                "gemini-1.5-pro"
            ];
        }

        candidatesIds = [...new Set(candidatesIds)];
        console.log("[åœ–åƒç”Ÿæˆ] æœ€çµ‚æ¨¡å‹å€™é¸åˆ—è¡¨:", candidatesIds);

        // 3. EXECUTION LOOP
        const tryImgModel = async (idx) => {
            if (idx >= candidatesIds.length) {
                console.error("æ‰€æœ‰åœ–åƒç”Ÿæˆæ¨¡å‹å¤±æ•—ã€‚");
                throw new Error(allErrors.join("\n\n"));
            }

            const modelId = candidatesIds[idx];
            console.log(`[åœ–åƒç”Ÿæˆ] å˜—è©¦ ${modelId}...`);
            if (onStatusUpdate) onStatusUpdate(`æ­£åœ¨åˆå§‹åŒ– ${modelId}...`);

            const url = `https://generativelanguage.googleapis.com/v1beta/models/${modelId}:generateContent?key=${apiKey}`;

            const parts = [];
            const aspectInstruction = aspectRatio === "3:4"
                ? "å‚ç›´è‚–åƒæ ¼å¼ï¼ˆé«˜æ–¼å¯¬ï¼Œ3:4 æ¯”ä¾‹ï¼‰"
                : "æ°´å¹³æ©«å‘æ ¼å¼ï¼ˆå¯¬æ–¼é«˜ï¼Œ4:3 æ¯”ä¾‹ï¼‰";

            let finalPrompt = '';

            // Append visual details if provided
            const visualContext = visualDetails ? `\n\nVISUAL & LOCATION CONSISTENCY LOCK (MANDATORY):\n${visualDetails}\nEnsure these visual details (appearance, environment, lighting) are strictly followed unless the scene description explicitly overrides them.` : "";

            // CRITICAL: Reference image instructions come FIRST for maximum priority
            if (referenceImageBase64) {
                finalPrompt = `ğŸ”´ CRITICAL PRIORITY - FACIAL IDENTITY LOCK ğŸ”´

                **MANDATORY REQUIREMENTS (HIGHEST PRIORITY):**
                1. The person in the generated image MUST have the EXACT SAME FACE as the attached reference image
                2. PRESERVE 100% FACIAL IDENTITY - same ethnicity, race, skin tone, facial structure, eye shape, nose, mouth
                3. DO NOT change the person's race or ethnicity under ANY circumstances
                4. This is the SAME PERSON performing in a movie scene - maintain complete facial consistency
                5. Match the reference photo's hairstyle, hair color, and facial features precisely
                6. If the reference shows an Asian person, the output MUST be Asian. If Caucasian, output MUST be Caucasian. If African, output MUST be African.
                
                ${visualContext}

                **SCENE DESCRIPTION (Secondary Priority):**
                Generate a photorealistic 8k image in ${aspectInstruction} format showing: ${prompt}
                
                **STYLE REQUIREMENTS:**
                - Photorealistic photography style (çœŸå¯¦æ”å½±ç…§ç‰‡é¢¨æ ¼)
                - Real human faces with skin texture
                - Absolutely NO anime, illustration, cartoon, or painting styles
                - Natural lighting and depth of field effects
                
                âš ï¸ REMINDER: The character's face, ethnicity, and race MUST match the reference image EXACTLY. This is non-negotiable.`;
            } else {
                finalPrompt = `ç”Ÿæˆä¸€å¼µçœŸå¯¦ç…§ç‰‡ç´šåˆ¥çš„ 8k åœ–åƒï¼Œæ ¼å¼ç‚º ${aspectInstruction}ï¼Œå…§å®¹ï¼š${prompt}ã€‚
                
                ${visualContext}

                é¢¨æ ¼è¦æ±‚ï¼š
                - å¿…é ˆæ˜¯çœŸå¯¦æ”å½±ç…§ç‰‡é¢¨æ ¼ï¼ˆphotorealisticï¼‰
                - çœŸå¯¦çš„äººé¡é¢å­”å’Œçš®è†šç´‹ç†
                - çµ•å°ä¸è¦å‹•æ¼«ã€æ’ç•«ã€å¡é€šæˆ–ç¹ªç•«é¢¨æ ¼
                - ä½¿ç”¨çœŸå¯¦çš„å…‰å½±å’Œæ™¯æ·±æ•ˆæœ`;
            }

            parts.push({ text: finalPrompt });

            if (referenceImageBase64) {
                const b64Data = referenceImageBase64.split(',')[1] || referenceImageBase64;
                const mimeType = referenceImageBase64.includes('image/png') ? 'image/png' : 'image/jpeg';
                parts.push({ inlineData: { mimeType: mimeType, data: b64Data } });
            }

            const body = { contents: [{ parts: parts }] };

            try {
                const response = await fetch(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(body)
                });
                const data = await response.json();

                if (data.error) {
                    const msg = `[${modelId}] éŒ¯èª¤: ${data.error.message || JSON.stringify(data.error)}`;
                    console.warn(msg);

                    // RETRY LOGIC for Quota (429)
                    if (data.error.code === 429 || msg.includes("Quota") || msg.includes("rate limit")) {
                        const waitMatch = msg.match(/retry in ([0-9.]+)(?:s|ms)/i);
                        let waitMs = 10000;
                        if (waitMatch && waitMatch[1]) {
                            waitMs = Math.ceil(parseFloat(waitMatch[1]) * 1000) + 2000;
                            console.warn(`[é…é¡] API è«‹æ±‚ç­‰å¾…ã€‚ç¡çœ  ${waitMs / 1000}ç§’...`);
                        } else {
                            console.warn(`[é…é¡] é”åˆ°é™åˆ¶ã€‚ç¡çœ  10ç§’...`);
                        }

                        const totalSeconds = Math.ceil(waitMs / 1000);
                        for (let s = totalSeconds; s > 0; s--) {
                            if (onStatusUpdate) onStatusUpdate(`é…é¡å·²é”ã€‚${s}ç§’å¾Œé‡è©¦...`);
                            await sleep(1000);
                        }

                        return tryImgModel(idx);
                    }

                    allErrors.push(msg);
                    return tryImgModel(idx + 1);
                }

                if (data.candidates && data.candidates[0].content && data.candidates[0].content.parts) {
                    for (const part of data.candidates[0].content.parts) {
                        if (part.inlineData && part.inlineData.mimeType.startsWith('image')) {
                            if (!lockedImageModel) {
                                lockedImageModel = modelId;
                                console.log(`[åœ–åƒç”Ÿæˆ] âœ… æ¨¡å‹å·²é–å®š: ${modelId}ï¼ˆå°‡ç”¨æ–¼æ‰€æœ‰å ´æ™¯ï¼‰`);
                            }
                            return `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`;
                        }
                    }
                }

                if (data.predictions && data.predictions[0] && data.predictions[0].bytesBase64Encoded) {
                    return `data:image/png;base64,${data.predictions[0].bytesBase64Encoded}`;
                }

                allErrors.push(`[${modelId}] æˆåŠŸä½†éŸ¿æ‡‰ä¸­æ²’æœ‰åœ–åƒæ•¸æ“šã€‚`);
                return tryImgModel(idx + 1);

            } catch (e) {
                const isNetworkError = e.message.includes("fetch") || e.message.includes("Network");

                if (isNetworkError && (!e.retryCount || e.retryCount < 3)) {
                    const retryCount = (e.retryCount || 0) + 1;
                    const waitTime = Math.pow(2, retryCount) * 1000;

                    console.warn(`[${modelId}] ç¶²çµ¡éŒ¯èª¤ã€‚é‡è©¦ ${retryCount}/3 åœ¨ ${waitTime / 1000}ç§’...`);
                    if (onStatusUpdate) onStatusUpdate(`ç¶²çµ¡å•é¡Œã€‚${waitTime / 1000}ç§’å¾Œé‡è©¦...`);

                    await sleep(waitTime);

                    e.retryCount = retryCount;
                    return tryImgModel(idx);
                }

                allErrors.push(`[${modelId}] ç¶²çµ¡éŒ¯èª¤: ${e.message}`);
                return tryImgModel(idx + 1);
            }
        };

        return tryImgModel(0);
    };

    // Helper: Generate Video with Veo 3.1 API
    const generateVeoVideo = async (apiKey, imageBase64, prompt, duration = 5, onStatusUpdate = null, visualDetails = '') => {
        const sleep = (ms) => new Promise(r => setTimeout(r, ms));
        const errors = [];

        const veoModels = [
            "veo-3.1-generate-preview",
            "veo-3.0-generate-001",
            "veo-3.0-fast-generate-001"
        ];

        for (const modelId of veoModels) {
            try {
                console.log(`[Veo] å˜—è©¦ ${modelId} é€šé predictLongRunning...`);
                const url = `https://generativelanguage.googleapis.com/v1beta/models/${modelId}:predictLongRunning?key=${apiKey}`;

                const imageList = Array.isArray(imageBase64) ? imageBase64 : [imageBase64];
                const parts = [];

                for (const img of imageList) {
                    if (!img) continue;
                    let b64Data;
                    let mimeType;
                    if (img.startsWith('data:')) {
                        b64Data = img.split(',')[1];
                        mimeType = img.split(';')[0].split(':')[1];
                    } else if (img.startsWith('blob:')) {
                        try {
                            const blobRes = await fetch(img);
                            const blob = await blobRes.blob();
                            b64Data = await new Promise((resolve, reject) => {
                                const reader = new FileReader();
                                reader.onloadend = () => resolve(reader.result.split(',')[1]);
                                reader.onerror = reject;
                                reader.readAsDataURL(blob);
                            });
                            mimeType = blob.type;
                        } catch (e) { continue; }
                    } else {
                        b64Data = img;
                        mimeType = 'image/jpeg';
                    }
                    parts.push({ inlineData: { mimeType, data: b64Data } });
                }

                // Enhanced prompt for Cantonese audio and clothing consistency
                // Append user's locked visual details if provided
                const visualDetailsText = visualDetails && visualDetails.trim()
                    ? `\n\nè¦–è¦ºä¸€è‡´æ€§è¦æ±‚ï¼š${visualDetails.trim()}`
                    : '';

                const enhancedPrompt = `ç”Ÿæˆä¸€æ®µ ${duration} ç§’çš„é›»å½±ç´šå½±ç‰‡ï¼ŒåŸºæ–¼ä»¥ä¸‹åˆ†é¡ï¼š${prompt}ã€‚
                
                é‡è¦è¦æ±‚ï¼š
                1. éŸ³é »ï¼šæ‰€æœ‰è§’è‰²å°ç™½å’Œæ—ç™½å¿…é ˆ100%ä½¿ç”¨å»£æ±è©±ï¼ˆç²µèª/Cantoneseï¼‰ã€‚
                2. æœè£ï¼šè§’è‰²å¿…é ˆä¿æŒèˆ‡åƒè€ƒåœ–åƒå®Œå…¨ç›¸åŒçš„æœè£ã€é«®å‹å’Œé…é£¾ã€‚
                3. éŸ³æ•ˆï¼šåŒ…å«è‡ªç„¶ç’°å¢ƒéŸ³æ•ˆå’Œé›»å½±èƒŒæ™¯éŸ³æ¨‚ã€‚
                4. å‹•ä½œï¼šç¢ºä¿å‹•ä½œé€¼çœŸä¸”é«˜ä¿çœŸåº¦ã€‚${visualDetailsText}
                
                CRITICAL: All dialogue and narration must be in Cantonese (å»£æ±è©±). Character clothing must match the reference image exactly.`;

                // Log the complete prompt for debugging
                console.log(`[Veo] å®Œæ•´æç¤ºè© (${modelId}):\n`, enhancedPrompt);
                if (onStatusUpdate) {
                    onStatusUpdate(`æº–å‚™æç¤ºè©: ${prompt.substring(0, 50)}...`);
                }

                parts.unshift({ text: enhancedPrompt });

                const requestPayload = {
                    instances: [{
                        prompt: enhancedPrompt,
                        image: (parts[1] && parts[1].inlineData && parts[1].inlineData.mimeType.startsWith('image/')) ? {
                            bytesBase64Encoded: parts[1].inlineData.data,
                            mimeType: parts[1].inlineData.mimeType
                        } : undefined,
                        video: (parts[1] && parts[1].inlineData && parts[1].inlineData.mimeType.startsWith('video/')) ? {
                            bytesBase64Encoded: parts[1].inlineData.data,
                            mimeType: parts[1].inlineData.mimeType
                        } : undefined
                    }]
                };

                if (onStatusUpdate) onStatusUpdate(`æ­£åœ¨è«‹æ±‚ ${modelId}...`);
                const response = await fetch(url, {
                    method: 'POST',
                    headers: { 'Content-Type': 'application/json' },
                    body: JSON.stringify(requestPayload)
                });

                const data = await response.json();

                if (!response.ok || data.error) {
                    const msg = data.error ? data.error.message : response.statusText;
                    console.warn(`[${modelId}] åˆå§‹åŒ–éŒ¯èª¤: ${msg}`);
                    errors.push(`[${modelId}] ${msg}`);
                    continue;
                }

                if (!data.name) {
                    errors.push(`[${modelId}] ç¼ºå°‘æ“ä½œåç¨±ã€‚`);
                    continue;
                }

                const opName = data.name;
                console.log(`[Veo] æ“ä½œå·²é–‹å§‹: ${opName}`);

                // --- POLLING ---
                let pollCount = 0;
                const maxPolls = 180;
                while (pollCount < maxPolls) {
                    pollCount++;
                    if (onStatusUpdate) onStatusUpdate(`è¼ªè©¢ ${modelId} (${pollCount * 5}ç§’)...`);

                    const pollUrl = `https://generativelanguage.googleapis.com/v1beta/${opName}?key=${apiKey}`;
                    const pollRes = await fetch(pollUrl);
                    const pollData = await pollRes.json();

                    if (pollData.done) {
                        if (pollData.error) {
                            throw new Error(`æ“ä½œå¤±æ•—: ${pollData.error.message}`);
                        }

                        const res = pollData.response || {};
                        console.log(`[Veo] æ“ä½œé€²åº¦: å®Œæˆã€‚éŸ¿æ‡‰çµæ§‹:`, res);

                        const mainRes = res.generateVideoResponse || res;
                        const videoCandidates = [];

                        if (mainRes.video) videoCandidates.push(mainRes.video);
                        if (Array.isArray(mainRes.videos)) {
                            mainRes.videos.forEach(v => videoCandidates.push(v.video || v));
                        }
                        if (Array.isArray(mainRes.generatedVideos)) {
                            mainRes.generatedVideos.forEach(v => videoCandidates.push(v.video || v));
                        }
                        if (Array.isArray(mainRes.generatedSamples)) {
                            mainRes.generatedSamples.forEach(s => {
                                if (s.video) videoCandidates.push(s.video);
                            });
                        }

                        for (const v of videoCandidates) {
                            let videoData = null;
                            if (v.bytesBase64Encoded) {
                                videoData = `data:video/mp4;base64,${v.bytesBase64Encoded}`;
                            } else if (v.uri) {
                                videoData = v.uri.includes('?') ? `${v.uri}&key=${apiKey}` : `${v.uri}?key=${apiKey}`;
                            }

                            if (videoData) {
                                console.log(`[Veo] âœ… å½±ç‰‡å·²å®šä½ï¼æ¨¡å‹: ${modelId}`);
                                return { videoBase64: videoData, model: modelId };
                            }
                        }

                        if (mainRes.candidates && mainRes.candidates[0].content && mainRes.candidates[0].content.parts) {
                            const part = mainRes.candidates[0].content.parts.find(p => p.inlineData && p.inlineData.mimeType.startsWith('video'));
                            if (part) {
                                return {
                                    videoBase64: `data:${part.inlineData.mimeType};base64,${part.inlineData.data}`,
                                    model: modelId
                                };
                            }
                        }

                        // Check for RAI (Responsible AI) safety filter blocking
                        if (mainRes.raiMediaFilteredCount && mainRes.raiMediaFilteredCount > 0) {
                            const reasons = mainRes.raiMediaFilteredReasons || [];
                            const reasonText = reasons.join(' ');
                            console.error(`[${modelId}] å®‰å…¨éæ¿¾å™¨é˜»æ­¢: ${reasonText}`);
                            throw new Error(`å…§å®¹å®‰å…¨éæ¿¾å™¨è§¸ç™¼: ${reasonText}\n\nå»ºè­°ï¼šè«‹ç°¡åŒ–å ´æ™¯æè¿°ï¼Œç§»é™¤å°ç™½ï¼Œåªæè¿°è¦–è¦ºå‹•ä½œã€‚ä¾‹å¦‚ï¼š"å¥³ä¸»è§’å¾®ç¬‘çœ‹è‘—ç”·ä¸»è§’" è€Œä¸æ˜¯ "å¥³ä¸»è§’è¬›ï¼šä½ å¥½éšä»”ï¼"`);
                        }

                        console.error(`[${modelId}] ç„¡æ³•æå–å½±ç‰‡ã€‚çµæ§‹:`, JSON.stringify(res));
                        throw new Error(`æˆåŠŸç‹€æ…‹ï¼Œä½†éŸ¿æ‡‰ä¸­æœªæ‰¾åˆ°å½±ç‰‡æ•¸æ“šã€‚å·²æª¢æŸ¥: video, videos, generatedVideos, generatedSamples, candidatesã€‚`);
                    }

                    await sleep(5000);
                }
                throw new Error("è¼ªè©¢è¶…æ™‚ã€‚");

            } catch (e) {
                console.warn(`[${modelId}] éŒ¯èª¤:`, e.message);
                errors.push(`[${modelId}] ${e.message}`);
            }
        }

        throw new Error("Veo3 ç”Ÿæˆå¤±æ•—ã€‚è¨ºæ–·:\n" + errors.join("\n"));
    };

    // 3. FFmpeg-Based Video Stitcher
    const stitchVideos = async (scenes, durationPerSceneMs = 5000) => {
        addProductionLog(`é–‹å§‹ FFmpeg å½±ç‰‡çµ„è£: ${scenes.length} å€‹å ´æ™¯ã€‚`, 'info');

        const SERVER_URL = 'http://localhost:3000';

        try {
            const videoScenes = scenes.filter(s => s.veoVideo);

            if (videoScenes.length === 0) {
                throw new Error('æœªæ‰¾åˆ°å½±ç‰‡ç‰‡æ®µé€²è¡Œåˆä½µã€‚è«‹å•Ÿç”¨ Veo 3.1 å½±ç‰‡ç”Ÿæˆã€‚');
            }

            addProductionLog(`æ‰¾åˆ° ${videoScenes.length} å€‹å½±ç‰‡ç‰‡æ®µé€²è¡Œåˆä½µã€‚`, 'info');

            // Step 1: Upload all video blobs to the server
            const uploadedPaths = [];
            for (let i = 0; i < videoScenes.length; i++) {
                const scene = videoScenes[i];
                addProductionLog(`æ­£åœ¨ä¸Šå‚³å ´æ™¯ ${i + 1}/${videoScenes.length} åˆ°ä¼ºæœå™¨...`, 'info');

                const response = await fetch(scene.veoVideo);
                const blob = await response.blob();

                const formData = new FormData();
                formData.append('video', blob, `scene-${i + 1}.mp4`);

                const uploadResponse = await fetch(`${SERVER_URL}/api/save-video`, {
                    method: 'POST',
                    body: formData
                });

                if (!uploadResponse.ok) {
                    throw new Error(`ä¸Šå‚³å ´æ™¯ ${i + 1} å¤±æ•—: ${uploadResponse.statusText}`);
                }

                const uploadResult = await uploadResponse.json();
                uploadedPaths.push(uploadResult.filePath);
                addProductionLog(`å ´æ™¯ ${i + 1} å·²ä¸Šå‚³: ${uploadResult.filename}`, 'success');
            }

            // Step 2: Request FFmpeg concatenation
            addProductionLog('æ­£åœ¨è«‹æ±‚ FFmpeg åˆä½µ...', 'info');
            const concatResponse = await fetch(`${SERVER_URL}/api/concat-videos`, {
                method: 'POST',
                headers: { 'Content-Type': 'application/json' },
                body: JSON.stringify({ videoPaths: uploadedPaths })
            });

            if (!concatResponse.ok) {
                const errorData = await concatResponse.json();
                throw new Error(`FFmpeg åˆä½µå¤±æ•—: ${errorData.error || concatResponse.statusText}`);
            }

            const concatResult = await concatResponse.json();
            addProductionLog(`FFmpeg æˆåŠŸ: ${concatResult.message}`, 'success');

            const finalVideoUrl = `${SERVER_URL}/output/${concatResult.filename}`;
            addProductionLog(`æœ€çµ‚å½±ç‰‡æº–å‚™å°±ç·’: ${concatResult.filename}`, 'success');

            return finalVideoUrl;

        } catch (error) {
            addProductionLog(`FFmpeg æ‹¼æ¥éŒ¯èª¤: ${error.message}`, 'error');
            console.error('FFmpeg æ‹¼æ¥å¤±æ•—:', error);
            throw error;
        }
    };

    // --- Main Workflow Trigger ---
    btnGenVideo.addEventListener('click', async () => {
        // Collect user scenes
        const userScenes = collectUserScenes();

        if (userScenes.length === 0) {
            alert('è«‹è‡³å°‘å¡«å¯«å ´æ™¯ 1ã€‚');
            return;
        }

        if (!state.femaleImg && !state.maleImg) {
            alert('è«‹è‡³å°‘ä¸Šå‚³ä¸€å¼µè§’è‰²ç…§ç‰‡ã€‚');
            return;
        }

        const originalBtnText = btnGenVideo.innerHTML;
        const visualDetails = document.getElementById('visual-details').value;
        const aspectRatio = document.getElementById('aspect-ratio').value;

        // Detect Character Mode
        const hasFemale = !!state.femaleImg;
        const hasMale = !!state.maleImg;
        const characterMode = (hasFemale && hasMale) ? "dual" : "solo";
        console.log(`[è§’è‰²æ¨¡å¼] ${characterMode.toUpperCase()} - å¥³ä¸»è§’: ${hasFemale}, ç”·ä¸»è§’: ${hasMale}`);

        btnGenVideo.disabled = true;
        btnGenVideo.innerHTML = `<i class="fa-solid fa-spinner fa-spin"></i> æ­£åœ¨åˆå§‹åŒ–...`;
        addProductionLog("æ­£åœ¨åˆå§‹åŒ–å½±ç‰‡ç”Ÿæˆæµç¨‹...", 'info');

        const apiKey = document.getElementById('api-key').value.trim();

        // Display screenplay
        setTimeout(async () => {
            const screenplay = userScenes;
            console.log("ä½¿ç”¨ç”¨æˆ¶æä¾›çš„å ´æ™¯:", screenplay);
            addProductionLog(`ç”¨æˆ¶æä¾›çš„å ´æ™¯ç¸½æ•¸: ${screenplay.length}`, 'success');

            btnGenVideo.innerHTML = `<i class="fa-solid fa-video"></i> æ­£åœ¨æ‹æ” ${screenplay.length} å€‹é›»å½±å ´æ™¯...`;
            imageGallery.innerHTML = '';

            const scriptBox = document.createElement('div');
            scriptBox.className = 'glass-card';
            scriptBox.style.marginBottom = '20px';
            scriptBox.style.padding = '15px';
            scriptBox.style.textAlign = 'left';
            scriptBox.style.gridColumn = '1 / -1';

            scriptBox.innerHTML = `
            <div style="display:flex; justify-content:space-between; align-items:center; margin-bottom:10px;">
                <h3 style="margin:0;"><i class="fa-solid fa-scroll"></i> å ´æ™¯åˆ—è¡¨</h3>
                <span class="badge" style="background:#4CAF50; padding:4px 8px; border-radius:4px; font-size:0.8em; color:white;">ç”¨æˆ¶è‡ªè¨‚</span>
            </div>
            <div style="max-height: 300px; overflow-y: auto; background: rgba(0,0,0,0.2); padding: 10px; border-radius: 8px;">
                <ul style="list-style:none; padding:0;">
                    ${screenplay.map(s => `<li style="margin-bottom:8px; padding-bottom:8px; border-bottom:1px solid rgba(255,255,255,0.1);">
                        <span class="badge" style="background:var(--primary-color); padding:2px 6px; border-radius:4px; font-size:0.8em; margin-right:5px;">${s.cameraMove}</span>
                        ${s.description}
                    </li>`).join('')}
                </ul>
            </div>`;
            imageGallery.appendChild(scriptBox);

            const statusMsg = document.createElement('div');
            statusMsg.className = 'placeholder-text';
            statusMsg.innerHTML = `<p><i class="fa-solid fa-clapperboard"></i> <strong>è£½ä½œç‹€æ…‹:</strong> å ´æ™¯å·²é–å®šã€‚æ­£åœ¨æ‹æ”...</p>`;
            imageGallery.appendChild(statusMsg);

            const delay = (ms) => new Promise(resolve => setTimeout(resolve, ms));
            const scenes = [];

            // Helper to update the UI gallery
            const renderGalleryItem = (sceneResult, idx) => {
                const div = document.createElement('div');
                div.className = 'gallery-item glass-card';

                const isAI = sceneResult.type.includes('AI') || sceneResult.type.includes('Veo');
                const isError = sceneResult.type.startsWith('éŒ¯èª¤');
                let badgeColor = isAI ? '#4CAF50' : '#F44336';

                let mediaContent = '';
                if (isError) {
                    mediaContent = `<div style="width:100%; height:150px; background:#330000; display:flex; align-items:center; justify-content:center; color:#ffcccc; font-size:0.8em; padding:10px; text-align:center;">
                        <i class="fa-solid fa-triangle-exclamation"></i> ${sceneResult.type}
                    </div>`;
                } else if (sceneResult.veoVideo) {
                    mediaContent = `<video src="${sceneResult.veoVideo}" controls loop muted style="width:100%; height:150px; object-fit:cover;"></video>`;
                } else {
                    mediaContent = `<img src="${sceneResult.url}" style="width:100%; height:150px; object-fit:cover;">`;
                }

                div.innerHTML = `
                    <div style="overflow:hidden; border-radius:8px; margin-bottom:0.2rem;">
                        ${mediaContent}
                    </div>
                    <div style="display:flex; justify-content:space-between; align-items:center; margin-bottom:0.5rem; padding:0 2px;">
                        <span style="background:rgba(0,0,0,0.6); padding:2px 6px; border-radius:4px; font-size:0.7em; margin-bottom:4px; display:inline-block; border:1px solid rgba(255,255,255,0.3); color:#fff;"><i class="fa-solid fa-video"></i> ${sceneResult.cameraMove}</span>
                        <span style="background:${badgeColor}; padding:2px 6px; border-radius:4px; font-size:0.7em; color:#fff;">${sceneResult.type}</span>
                    </div>
                    <div class="scene-caption"><i class="fa-solid fa-quote-left"></i> ${sceneResult.description}</div>
                    <div style="display:flex; gap:5px; margin-top:10px;">
                        ${!isError ? `
                            <button onclick="downloadImage('${sceneResult.url}', 'scene_${idx + 1}.png')" class="glass-btn" style="flex:1; font-size:0.75em; padding:8px 0;">
                                <i class="fa-solid fa-image"></i> ç²å–ç…§ç‰‡
                            </button>
                            ${sceneResult.veoVideo ? `
                            <button onclick="downloadImage('${sceneResult.veoVideo}', 'scene_${idx + 1}.mp4')" class="glass-btn" style="flex:1; font-size:0.75em; padding:8px 0; border-color: #4CAF50; color: #4CAF50;">
                                <i class="fa-solid fa-file-video"></i> ç²å–å½±ç‰‡
                            </button>
                            ` : ''}
                        ` : ''}
                    </div>
                `;
                imageGallery.appendChild(div);
            };

            for (let i = 0; i < screenplay.length; i++) {
                const scene = screenplay[i];
                const sceneNum = i + 1;

                btnGenVideo.innerHTML = `<i class="fa-solid fa-paintbrush"></i> æ­£åœ¨ç”Ÿæˆå ´æ™¯ ${sceneNum}/${screenplay.length}...`;
                addProductionLog(`æ­£åœ¨ç”Ÿæˆå ´æ™¯ ${sceneNum}/${screenplay.length}: "${scene.description}"`, 'info');

                let sceneResult = { ...scene, url: '', veoVideo: null, type: 'åˆå§‹åŒ–' };

                try {
                    const promptToUse = scene.image_prompt_en || scene.description;

                    let refImage = state.femaleImg;
                    if (scene.cameraMove.includes("ç”·è§’") && state.maleImg) {
                        refImage = state.maleImg;
                    } else if (scene.cameraMove.includes("Male") && state.maleImg) {
                        refImage = state.maleImg;
                    }

                    // 1. Generate Static Reference Image
                    addProductionLog(`AI åœ–åƒ [S${sceneNum}]: æ­£åœ¨ç”ŸæˆåŸºç¤åœ–åƒ...`, 'info');
                    const aiUrl = await generateAIImage(apiKey, promptToUse, refImage, (statusMsg) => {
                        btnGenVideo.innerHTML = `<i class="fa-solid fa-hourglass-half"></i> å ´æ™¯ ${sceneNum}: ${statusMsg}`;
                        addProductionLog(`AI åœ–åƒ [S${sceneNum}]: ${statusMsg}`, 'info');
                    }, aspectRatio, visualDetails);

                    if (aiUrl) {
                        sceneResult.url = aiUrl;
                        sceneResult.type = lockedImageModel || 'AI ç”Ÿæˆå™¨';
                        addProductionLog(`AI åœ–åƒ [S${sceneNum}]: âœ… åŸºç¤åœ–åƒå·²ç”± ${sceneResult.type} ç”Ÿæˆã€‚`, 'success');

                        // 2. Generate Veo3 Video Clip if enabled
                        const veoEnabled = document.getElementById('enable-veo').checked;
                        if (veoEnabled) {
                            try {
                                addProductionLog(`æ­£åœ¨ç”¨ Veo 3.1 æ‹æ”å ´æ™¯ ${sceneNum}...`, 'info');
                                btnGenVideo.innerHTML = `<i class="fa-solid fa-film"></i> Veo3: æ­£åœ¨ç”Ÿæˆç‰‡æ®µ ${i + 1}/${screenplay.length}... (è«‹ç¨å€™)`;

                                const targetDuration = 8; // Fixed 8 seconds per scene
                                const veoResult = await generateVeoVideo(apiKey, aiUrl, promptToUse, targetDuration, (status) => {
                                    btnGenVideo.innerHTML = `<i class="fa-solid fa-film"></i> Veo3: ${status} (å ´æ™¯ ${i + 1})`;
                                    addProductionLog(`Veo3 [S${sceneNum}]: ${status}`, 'info');
                                }, visualDetails);

                                if (veoResult && veoResult.videoBase64) {
                                    sceneResult.veoVideo = veoResult.videoBase64;
                                    sceneResult.type = `Veo 3.1 (é›»å½±)`;
                                    addProductionLog(`Veo3 [S${sceneNum}]: âœ… å½±ç‰‡æˆåŠŸæ•ç²ï¼`, 'success');
                                }
                            } catch (veoErr) {
                                addProductionLog(`Veo3 [S${sceneNum}]: âŒ å¤±æ•— - ${veoErr.message}`, 'error');
                                console.warn(`å ´æ™¯ ${sceneNum} çš„ Veo å¤±æ•—:`, veoErr.message);
                            }
                        }
                    } else {
                        throw new Error("AI åœ–åƒç”Ÿæˆå¤±æ•—ã€‚");
                    }
                } catch (e) {
                    addProductionLog(`å ´æ™¯ ${sceneNum} è£½ä½œéŒ¯èª¤: ${e.message}`, 'error');
                    console.error(`å ´æ™¯ ${sceneNum} å¤±æ•—:`, e);
                    sceneResult.type = 'éŒ¯èª¤: ' + e.message;
                }

                scenes.push(sceneResult);
                renderGalleryItem(sceneResult, i);

                if (i < screenplay.length - 1) await delay(1000);
            }

            // --- Step 3: Stitching Final Movie ---
            btnGenVideo.innerHTML = `<i class="fa-solid fa-film"></i> æœ€çµ‚å½±ç‰‡çµ„è£ä¸­...`;
            addProductionLog("é–‹å§‹å½±ç‰‡çµ„è£å’Œå…¨å±€éŸ³é »åŒæ­¥...", 'info');

            try {
                const sceneDuration = 8000; // 8 seconds per scene
                addProductionLog(`æ‹¼æ¥: ${screenplay.length} å€‹å ´æ™¯ï¼Œæ¯å€‹ ${sceneDuration}ms`, 'info');

                let finalVideoUrl;
                if (scenes.length === 1 && scenes[0].veoVideo) {
                    addProductionLog("ç›´æ¥äº¤ä»˜: æª¢æ¸¬åˆ°å–®å€‹ Veo å ´æ™¯ã€‚ç¹éç•«å¸ƒæ‹¼æ¥å™¨ä»¥ç²å¾—æœ€å¤§è³ªé‡ã€‚", 'success');
                    finalVideoUrl = scenes[0].veoVideo;
                } else {
                    finalVideoUrl = await stitchVideos(scenes, sceneDuration);
                }

                videoSection.classList.remove('hidden');
                videoSection.scrollIntoView({ behavior: 'smooth' });
                finalVideo.src = finalVideoUrl;
                finalVideo.load();
                finalVideo.play();

                let caption = document.getElementById('video-caption') || document.createElement('p');
                caption.id = 'video-caption';
                caption.className = 'scene-caption';
                caption.style.textAlign = 'center';
                caption.style.marginTop = '10px';
                if (!document.getElementById('video-caption')) finalVideo.parentElement.appendChild(caption);

                const realVeoCount = scenes.filter(s => !!s.veoVideo).length;
                caption.innerHTML = `<strong>æœ€çµ‚è£½ä½œ:</strong> ${realVeoCount}/${scenes.length} å€‹å ´æ™¯åŒ…å«çœŸå¯¦ Veo3 å½±ç‰‡å’Œç´” AI éŸ³é »ã€‚`;
                addProductionLog(`è£½ä½œå®Œæˆï¼çœŸå¯¦ Veo ç‰‡æ®µç¸½æ•¸: ${realVeoCount}`, 'success');

                const dlLink = document.getElementById('download-link');
                dlLink.href = finalVideoUrl;
                dlLink.download = `cinema_production_${Date.now()}.mp4`;
                dlLink.innerHTML = `<i class="fa-solid fa-download"></i> ä¸‹è¼‰å®Œæ•´é›»å½± MP4`;

                // Add Raw Batch Download Link
                const rawVeos = scenes.filter(s => !!s.veoVideo);
                if (rawVeos.length > 0) {
                    const batchContainer = document.createElement('div');
                    batchContainer.style.marginTop = '15px';
                    batchContainer.style.textAlign = 'center';

                    const btnAll = document.createElement('button');
                    btnAll.className = 'glass-btn';
                    btnAll.style.borderColor = '#4CAF50';
                    btnAll.style.color = '#4CAF50';
                    btnAll.innerHTML = `<i class="fa-solid fa-file-zipper"></i> ä¸‹è¼‰æ‰€æœ‰ ${rawVeos.length} å€‹åŸå§‹ Veo ç‰‡æ®µ`;
                    btnAll.onclick = () => {
                        rawVeos.forEach((s, idx) => {
                            setTimeout(() => {
                                downloadImage(s.veoVideo, `raw_veo_scene_${idx + 1}.mp4`);
                            }, idx * 500);
                        });
                    };
                    batchContainer.appendChild(btnAll);
                    dlLink.parentElement.appendChild(batchContainer);
                }
            } catch (stitchErr) {
                addProductionLog(`çµ„è£å¤±æ•—: ${stitchErr.message}`, 'error');
                console.error("æ‹¼æ¥å¤±æ•—:", stitchErr);
                alert("çµ„è£å¤±æ•—ï¼Œä½†æ‚¨å¯ä»¥ä¸‹è¼‰ä¸Šé¢çš„å–®å€‹å ´æ™¯ã€‚");
            }

            btnGenVideo.innerHTML = originalBtnText;
            btnGenVideo.disabled = false;

        }, 1500);
    });

});
